{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFN5zOAX4Khs",
        "outputId": "60f124c3-0b4d-46ad-acea-97daee25c49b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/89.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m81.9/89.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.6/15.6 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.2/261.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyjsparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet apache-beam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apache Beam Pipeline for Transforming and Printing Data"
      ],
      "metadata": {
        "id": "eqUsunPp8KDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "\n",
        "def process_word(word):\n",
        "    return f\"{word}: {len(word)} characters\"\n",
        "\n",
        "# Set up pipeline options\n",
        "pipeline_options = PipelineOptions()\n",
        "\n",
        "# Create the pipeline\n",
        "with beam.Pipeline(options=pipeline_options) as pipeline:\n",
        "\n",
        "    # Create initial PCollection\n",
        "    words = pipeline | \"Generate Words\" >> beam.Create([\n",
        "        \"Data\", \"Processing\", \"with\", \"Apache\", \"Beam\"\n",
        "    ])\n",
        "\n",
        "    # Apply transformations\n",
        "    processed_words = (words\n",
        "        | \"Add Length Info\" >> beam.Map(process_word)\n",
        "        | \"To Lowercase\" >> beam.Map(str.lower)\n",
        "    )\n",
        "\n",
        "    # Output results\n",
        "    processed_words | \"Display Results\" >> beam.Map(print)\n",
        "\n",
        "# Pipeline runs automatically due to the 'with' statement"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "b0CaROob4ktu",
        "outputId": "6ad2ae17-2d2d-41e0-a93c-8975c6f44343"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-8fcc2ebc-5c7f-4a9d-bf77-ed1484ea4803.json']\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-8fcc2ebc-5c7f-4a9d-bf77-ed1484ea4803.json']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: 4 characters\n",
            "processing: 10 characters\n",
            "with: 4 characters\n",
            "apache: 6 characters\n",
            "beam: 4 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Composite Transform\n",
        "I've implemented composite transform called **TextAnalyzer** using beam.PTransform.\n",
        "\n",
        "*   It takes a PCollection of strings.\n",
        "*   Calculates the length of each string using beam.Map.\n",
        "*   Formats the output as \"string: length letters\" using beam.Map."
      ],
      "metadata": {
        "id": "JQUL4SXr8u8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "\n",
        "class TextAnalyzer(beam.PTransform):\n",
        "    def expand(self, pcoll):\n",
        "        return (pcoll\n",
        "                | 'Count Characters' >> beam.Map(lambda x: (x, len(x)))\n",
        "                | 'Format Output' >> beam.Map(lambda x: f\"{x[0]}: {x[1]} letters\"))\n",
        "\n",
        "# Set up pipeline options\n",
        "options = PipelineOptions()\n",
        "\n",
        "# Create and run the pipeline\n",
        "with beam.Pipeline(options=options) as pipeline:\n",
        "    result = (pipeline\n",
        "              | 'Create Input' >> beam.Create(['python', 'apache', 'beam', 'dataflow'])\n",
        "              | 'Analyze Text' >> TextAnalyzer()\n",
        "              | 'Display Results' >> beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goEORKpd5ff-",
        "outputId": "622a2eae-7c98-4a4b-bf38-204a9932ffb3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-8fcc2ebc-5c7f-4a9d-bf77-ed1484ea4803.json']\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-8fcc2ebc-5c7f-4a9d-bf77-ed1484ea4803.json']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python: 6 letters\n",
            "apache: 6 letters\n",
            "beam: 4 letters\n",
            "dataflow: 8 letters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline IO"
      ],
      "metadata": {
        "id": "_72Sn_Or87zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline(options=options) as p:\n",
        "    (p\n",
        "     | 'Read File' >> beam.io.ReadFromText('/content/drive/MyDrive/ProjectsData/KDD_Detailed_description.txt')\n",
        "     | 'Process Text' >> beam.Map(lambda x: x.upper())\n",
        "     | 'Write Results' >> beam.io.WriteToText('/content/drive/MyDrive/ProjectsData/KDD_Detailed_description_uppercase.txt')\n",
        "    )\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60IlUKq37lom",
        "outputId": "175dea83-936e-4210-9d17-d50f11b18f3e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-8fcc2ebc-5c7f-4a9d-bf77-ed1484ea4803.json']\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-8fcc2ebc-5c7f-4a9d-bf77-ed1484ea4803.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Triggers\n",
        "Using triggers in Apache Beam pipelines to control when data is processed within a window.\n",
        "\n",
        "*   It simulates a data stream using data\\_generator which yields data points with a random integer and sleeps for 0.8 seconds between each yield to simulate real-time data arrival.\n",
        "\n",
        "*   The pipeline uses a sliding window of 4 seconds with a 2-second period, meaning a new window starts every 2 seconds and considers the last 4 seconds of data."
      ],
      "metadata": {
        "id": "4K-gNj2t9XfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "from apache_beam.transforms import window\n",
        "from apache_beam.transforms import trigger\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "import random\n",
        "import time\n",
        "\n",
        "def data_generator():\n",
        "    for i in range(15):\n",
        "        yield f\"data_point_{random.randint(1, 100)}\"\n",
        "        time.sleep(0.8)  # Simulates data arriving every 0.8 seconds\n",
        "\n",
        "pipeline_config = PipelineOptions()\n",
        "\n",
        "with beam.Pipeline(options=pipeline_config) as pipeline:\n",
        "    (pipeline\n",
        "     | 'Ingest Data' >> beam.Create(data_generator())\n",
        "     | 'Apply Windowing' >> beam.WindowInto(\n",
        "         window.SlidingWindows(4, 2),\n",
        "         trigger=trigger.AfterWatermark(early=trigger.AfterCount(3)),\n",
        "         accumulation_mode=trigger.AccumulationMode.ACCUMULATING\n",
        "     )\n",
        "     | 'Process and Log' >> beam.Map(lambda element: print(f\"Processed: {element}\"))\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3xZVkYX9Ldd",
        "outputId": "84a137f6-d344-4283-8878-d1f977549fac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-8fcc2ebc-5c7f-4a9d-bf77-ed1484ea4803.json']\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-8fcc2ebc-5c7f-4a9d-bf77-ed1484ea4803.json']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed: data_point_57\n",
            "Processed: data_point_71\n",
            "Processed: data_point_36\n",
            "Processed: data_point_1\n",
            "Processed: data_point_52\n",
            "Processed: data_point_26\n",
            "Processed: data_point_90\n",
            "Processed: data_point_33\n",
            "Processed: data_point_83\n",
            "Processed: data_point_34\n",
            "Processed: data_point_56\n",
            "Processed: data_point_97\n",
            "Processed: data_point_73\n",
            "Processed: data_point_99\n",
            "Processed: data_point_87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Windowing\n",
        "*   The pipeline employs sliding windows\n",
        "with a 4-second window duration and a 2-second sliding period.\n",
        "*   This means a new window starts every 2 seconds and encompasses the last 4 seconds of data."
      ],
      "metadata": {
        "id": "0bZuKecP9b9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_stream_simulator():\n",
        "    for _ in range(12):\n",
        "        yield f\"item_{random.randint(100, 999)}\"\n",
        "        time.sleep(0.8)  # Simulates data arriving every 0.8 seconds\n",
        "\n",
        "pipeline_settings = PipelineOptions()\n",
        "\n",
        "with beam.Pipeline(options=pipeline_settings) as data_pipeline:\n",
        "    (data_pipeline\n",
        "     | 'Ingest Streaming Data' >> beam.Create(data_stream_simulator())\n",
        "     | 'Apply Sliding Windows' >> beam.WindowInto(window.SlidingWindows(4, 2))\n",
        "     | 'Process and Display' >> beam.Map(lambda element: print(f\"Processed in window: {element}\"))\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slh9u8Kn9cck",
        "outputId": "c2f477fa-f515-41e9-d1ab-de5e226e8dee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-8fcc2ebc-5c7f-4a9d-bf77-ed1484ea4803.json']\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-8fcc2ebc-5c7f-4a9d-bf77-ed1484ea4803.json']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed in window: item_349\n",
            "Processed in window: item_170\n",
            "Processed in window: item_360\n",
            "Processed in window: item_955\n",
            "Processed in window: item_777\n",
            "Processed in window: item_442\n",
            "Processed in window: item_210\n",
            "Processed in window: item_182\n",
            "Processed in window: item_199\n",
            "Processed in window: item_124\n",
            "Processed in window: item_552\n",
            "Processed in window: item_346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ParDo\n",
        "*   It allows you to apply a user-defined function to each element in a PCollection.\n",
        "*   The process method within EnhanceData takes an element, capitalizes it, adds \"[enhanced]\" to it, and yields the modified element."
      ],
      "metadata": {
        "id": "l0fK4tIW9rNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhanceData(beam.DoFn):\n",
        "    def process(self, item):\n",
        "        enhanced = f\"{item.capitalize()} [enhanced]\"\n",
        "        yield enhanced\n",
        "\n",
        "pipeline_config = PipelineOptions()\n",
        "\n",
        "with beam.Pipeline(options=pipeline_config) as data_pipeline:\n",
        "    (data_pipeline\n",
        "     | 'Generate Input' >> beam.Create(['apple', 'banana', 'cherry', 'date'])\n",
        "     | 'Enhance Items' >> beam.ParDo(EnhanceData())\n",
        "     | 'Display Results' >> beam.Map(lambda x: print(f\"Processed: {x}\"))\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Olv9kwn39pG0",
        "outputId": "da21bd62-f1d1-4e03-bff4-72dac25e64fd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-8fcc2ebc-5c7f-4a9d-bf77-ed1484ea4803.json']\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-8fcc2ebc-5c7f-4a9d-bf77-ed1484ea4803.json']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed: Apple [enhanced]\n",
            "Processed: Banana [enhanced]\n",
            "Processed: Cherry [enhanced]\n",
            "Processed: Date [enhanced]\n"
          ]
        }
      ]
    }
  ]
}